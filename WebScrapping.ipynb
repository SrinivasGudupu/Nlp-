{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    " \n",
    "\n",
    "# URL to scrape\n",
    "\n",
    "url = \"http://quotes.toscrape.com/\"\n",
    "\n",
    " \n",
    "\n",
    "# Send a GET request\n",
    "\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\" - Albert Einstein\n",
      "   Tags: change, deep-thoughts, thinking, world\n",
      "\n",
      "2. \"“It is our choices, Harry, that show what we truly are, far more than our abilities.”\" - J.K. Rowling\n",
      "   Tags: abilities, choices\n",
      "\n",
      "3. \"“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\" - Albert Einstein\n",
      "   Tags: inspirational, life, live, miracle, miracles\n",
      "\n",
      "4. \"“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\" - Jane Austen\n",
      "   Tags: aliteracy, books, classic, humor\n",
      "\n",
      "5. \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\" - Marilyn Monroe\n",
      "   Tags: be-yourself, inspirational\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Check if the request was successful\n",
    "\n",
    "if response.status_code == 200:\n",
    "\n",
    "    # Parse the HTML\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    " \n",
    "\n",
    "    # Find all quote containers\n",
    "\n",
    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
    "\n",
    " \n",
    "\n",
    "    # Loop through each quote and extract data\n",
    "\n",
    "    for i, quote in enumerate(quotes[:5]):  # Get first 5 quotes\n",
    "\n",
    "        text = quote.find(\"span\", class_=\"text\").text  # Quote text\n",
    "\n",
    "        author = quote.find(\"small\", class_=\"author\").text  # Author name\n",
    "\n",
    "        tags = [tag.text for tag in quote.find_all(\"a\", class_=\"tag\")]  # List of tags\n",
    "\n",
    "        \n",
    "\n",
    "        print(f\"{i+1}. \\\"{text}\\\" - {author}\")\n",
    "\n",
    "        print(f\"   Tags: {', '.join(tags)}\\n\")\n",
    "\n",
    "else:\n",
    "\n",
    "    print(f\"Failed to retrieve the webpage. Status Code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    " \n",
    "\n",
    "# Define the city (e.g., New York)\n",
    "\n",
    "city = \"india/hyderabad\"\n",
    "\n",
    " \n",
    "\n",
    "# Weather URL\n",
    "\n",
    "url = f\"https://www.timeanddate.com/weather/{city}\"\n",
    "\n",
    " \n",
    "\n",
    "# Send GET request\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Weather in Hyderabad: 28 °C | Haze.\n"
     ]
    }
   ],
   "source": [
    "# Extract temperature and description\n",
    "\n",
    "temp = soup.find(\"div\", class_=\"h2\").text.strip() if soup.find(\"div\", class_=\"h2\") else \"N/A\"\n",
    "\n",
    "desc = soup.find(\"p\").text.strip() if soup.find(\"p\") else \"N/A\"\n",
    "\n",
    " \n",
    "\n",
    "print(f\"Current Weather in Hyderabad: {temp} | {desc}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find product details.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    " \n",
    "\n",
    "# Product search URL (Example: bike)\n",
    "\n",
    "search_url = \"https://www.amazon.in/Hero-Glamour-Blazing-Booking-Ex-Showroom/dp/B0D9DLDXNH/?_encoding=UTF8&pd_rd_w=fSr8b&content-id=amzn1.sym.2273b6ac-d102-4f60-980f-7b11bf59f079&pf_rd_p=2273b6ac-d102-4f60-980f-7b11bf59f079&pf_rd_r=4REGACXJQWQKFM4YHPST&pd_rd_wg=D0bco&pd_rd_r=e4345282-5078-4cef-be5d-7f8effdf0807&ref_=pd_hp_d_btf_ls_gwc_pc_en4_&th=1\"\n",
    "\n",
    " \n",
    "\n",
    "# Headers (Mimic a browser)\n",
    "\n",
    "headers = {\n",
    "\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "\n",
    "}\n",
    "\n",
    "# Send GET request\n",
    "\n",
    "response = requests.get(search_url, headers=headers)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    " \n",
    "\n",
    "# Extract first product name & price\n",
    "\n",
    "product = soup.select_one(\"span.a-size-medium\")\n",
    "\n",
    "price = soup.select_one(\"span.a-price-whole\")\n",
    "\n",
    " \n",
    "\n",
    "# Display product details\n",
    "\n",
    "if product and price:\n",
    "\n",
    "    print(f\"Product: {product.text.strip()}\")\n",
    "\n",
    "    print(f\"Price: ${price.text.strip()}\")\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Could not find product details.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World: 8,119,000,000\n",
      "China: 1,408,280,000\n",
      "1,402,737,000: 17.2%\n",
      "United States: 340,110,988\n",
      "Indonesia: 282,477,584\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    " \n",
    "\n",
    "# Wikipedia page URL\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population\"\n",
    "\n",
    " \n",
    "\n",
    "# Send GET request\n",
    "\n",
    "response = requests.get(url,headers=headers)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    " \n",
    "\n",
    "# Find the table\n",
    "\n",
    "table = soup.find(\"table\", class_=\"wikitable\")\n",
    "\n",
    "# Extract the first 5 countries and their population\n",
    "\n",
    "for row in table.find_all(\"tr\")[1:6]:  # Skip the header row\n",
    "\n",
    "    columns = row.find_all(\"td\")\n",
    "\n",
    "    country = columns[1].text.strip()\n",
    "\n",
    "    population = columns[2].text.strip()\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"{country}: {population}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World: 8,119,000,000\n",
      "China: 1,408,280,000\n",
      "1,402,737,000: 17.2%\n",
      "United States: 340,110,988\n",
      "Indonesia: 282,477,584\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    " \n",
    "\n",
    "# Wikipedia page URL\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population\"\n",
    "\n",
    " \n",
    "\n",
    "# Send GET request\n",
    "\n",
    "response = requests.get(url,headers=headers)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    " \n",
    "\n",
    "# Find the table\n",
    "\n",
    "table = soup.find(\"table\", class_=\"wikitable\")\n",
    "\n",
    "# Extract the first 5 countries and their population\n",
    "\n",
    "for row in table.find_all(\"tr\")[1:6]:  # Skip the header row\n",
    "\n",
    "    columns = row.find_all(\"td\")\n",
    "\n",
    "    country = columns[1].text.strip()\n",
    "\n",
    "    population = columns[2].text.strip()\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"{country}: {population}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "\n",
       "  <tr>\n",
       "\n",
       "    <th>Company</th>\n",
       "\n",
       "    <th>Contact</th>\n",
       "\n",
       "    <th>Country</th>\n",
       "\n",
       "  </tr>\n",
       "\n",
       "  <tr>\n",
       "\n",
       "    <td>Alfreds Futterkiste</td>\n",
       "\n",
       "    <td>Maria Anders</td>\n",
       "\n",
       "    <td>Germany</td>\n",
       "\n",
       "  </tr>\n",
       "\n",
       "  <tr>\n",
       "\n",
       "    <td>Centro comercial Moctezuma</td>\n",
       "\n",
       "    <td>Francisco Chang</td>\n",
       "\n",
       "    <td>Mexico</td>\n",
       "\n",
       "  </tr>\n",
       "\n",
       "</table>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"\"\"<table>\n",
    "\n",
    "  <tr>\n",
    "\n",
    "    <th>Company</th>\n",
    "\n",
    "    <th>Contact</th>\n",
    "\n",
    "    <th>Country</th>\n",
    "\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "\n",
    "    <td>Alfreds Futterkiste</td>\n",
    "\n",
    "    <td>Maria Anders</td>\n",
    "\n",
    "    <td>Germany</td>\n",
    "\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "\n",
    "    <td>Centro comercial Moctezuma</td>\n",
    "\n",
    "    <td>Francisco Chang</td>\n",
    "\n",
    "    <td>Mexico</td>\n",
    "\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
